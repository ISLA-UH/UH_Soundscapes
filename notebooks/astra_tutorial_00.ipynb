{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9827e2e-92c7-4c19-a2c9-f70e11ebd68b",
   "metadata": {},
   "source": [
    "# Acoustic Rocket Dataset Tutorial: Loading, Filtering, Plotting, and Saving ASTRA Data\n",
    "\n",
    "This tutorial goes over the basics of how to read, filter, and plot data from Aggregated Smartphone Timeseries of Rocket-generated Acoustics (ASTRA), an open-access dataset.\n",
    "\n",
    "A PKL file containing a single recording from ASTRA is included with this tutorial. The full ASTRA dataset can be downloaded from __[Harvard Dataverse](https://doi.org/10.7910/DVN/ZKIS2K)__ or __[Soundscapes Archive](https://www.higp.hawaii.edu/archive/isla/UH_Soundscapes/ASTRA/)__.\n",
    "\n",
    "For details on the dataset and the software used to collect and store the data, see __[Popenhagen and Garces (2025)](https://doi.org/10.3390/signals6010005)__ and __[Garces, et al. (2020)](https://doi.org/10.3390/signals3020014)__, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd4c7f7",
   "metadata": {},
   "source": [
    "## Section 0: Prerequisites and Imports\n",
    "The following cell includes the imports necessary to run this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c63af8-7640-43a7-8e3c-f636870e4f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone\n",
    "from quantum_inferno.plot_templates.plot_templates_examples import plot_wf_mesh_vert_example\n",
    "from quantum_inferno.cwt_atoms import cwt_chirp_from_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59505de5-3a00-4310-9ec0-54e3eca99309",
   "metadata": {},
   "source": [
    "## Section 1: Loading the Dataset\n",
    "\n",
    "In the following cell, we'll define the path to the dataset. By default, this path will point to the single-recording subset of ASTRA included with this tutorial.\n",
    "\n",
    "After you've completed the tutorial with this file, feel free to download the full ASTRA dataset and use the last line of the cell to change the 'PATH_TO_PKL' variable to point to its location on your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263ebaa-131d-48e2-9db0-6f309772d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUTORIAL_PICKLE_FILE_NAME = \"ASTRA_tutorial.pkl\"\n",
    "CURRENT_DIRECTORY = os.getcwd()\n",
    "PATH_TO_TUTORIAL_PKL = os.path.join(CURRENT_DIRECTORY, TUTORIAL_PICKLE_FILE_NAME)\n",
    "PATH_TO_PKL = PATH_TO_TUTORIAL_PKL\n",
    "# PATH_TO_PKL = \"<insert path to ASTRA.pkl on your device here>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b11af7-fe5f-435d-8dc6-3bbed89622a4",
   "metadata": {},
   "source": [
    "Once we have the location of the file, we can read the data using the pandas module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a34be7-1910-40b5-bf30-d5dd776e0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "astra_ds = pd.read_pickle(PATH_TO_PKL)\n",
    "astra_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efa308-5fad-4f07-8357-527b22ffd0aa",
   "metadata": {},
   "source": [
    "Each row of the pandas DataFrame contains all data and metadata from a single recording in ASTRA, with individual columns for each of the available fields.\n",
    "\n",
    "To keep track of all the column names, we'll define the 'ASTRALabels' class, and then initiate an instance of it in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b5767e-add7-4000-841d-6e41e0db6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASTRALabels:\n",
    "    \"\"\"\n",
    "    A class containing the column names used in ASTRA.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            station_id: str = \"station_id\",\n",
    "            station_make: str = \"station_make\",\n",
    "            station_model: str = \"station_model_number\",\n",
    "            audio_data: str = \"audio_wf_raw\",\n",
    "            first_sample_epoch_s: str = \"first_sample_epoch_s\",\n",
    "            audio_fs: str = \"audio_sample_rate_nominal_hz\",\n",
    "            station_lat: str = \"station_latitude\",\n",
    "            station_lon: str = \"station_longitude\",\n",
    "            launch_id: str = \"launch_id\",\n",
    "            launch_pad_lat: str = \"launch_pad_latitude\",\n",
    "            launch_pad_lon: str = \"launch_pad_longitude\",\n",
    "            reported_launch_epoch_s: str = \"reported_launch_epoch_s\",\n",
    "            s_aligned_toa_est: str = \"start_aligned_arrival_time_estimate_epoch_s\",\n",
    "            p_aligned_toa_est: str = \"peak_aligned_arrival_time_estimate_epoch_s\",\n",
    "            est_prop_dist_km: str = \"estimated_propagation_distance_km\",\n",
    "            rocket_type: str = \"rocket_type\",\n",
    "            rocket_model_number: str = \"rocket_model_number\",\n",
    "            n_srbs: str = \"n_solid_rocket_boosters\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Defaults should be left in place for most uses.\n",
    "        :param station_id: column containing the recording smartphones' unique station ID numbers\n",
    "        :param station_make: column containing the recording smartphones' makes\n",
    "        :param station_model: column containing the recording smartphones' models\n",
    "        :param audio_data: column containing the raw, uncalibrated audio data\n",
    "        :param first_sample_epoch_s: column containing the epoch second of the first sample\n",
    "        :param audio_fs: column containing the sample rate of the audio data in Hertz\n",
    "        :param station_lat: column containing the recording smartphones' latitude in degrees\n",
    "        :param station_lon: column containing the recording smartphones' longitude in degrees\n",
    "        :param launch_id: column containing the launches' unique ID strings\n",
    "        :param launch_pad_lat: column containing the launch pad latitudes in degrees\n",
    "        :param launch_pad_lon: column containing the launch pad longitudes in degrees\n",
    "        :param reported_launch_epoch_s: column containing the reported launch times in epoch seconds\n",
    "        :param s_aligned_toa_est: column containing the start-aligned arrival time estimates in epoch seconds\n",
    "        :param p_aligned_toa_est: column containing the peak-aligned arrival time estimates in epoch seconds\n",
    "        :param est_prop_dist_km: column containing the estimated propagation distances in kilometers\n",
    "        :param rocket_type: column containing the type of rockets launched (ex: \"SpaceX Falcon 9\")\n",
    "        :param rocket_model_number: column containing the model number of the rockets launched (ex: \"F9-B5\")\n",
    "        :param n_srbs: column containing the number of solid rocket boosters used\n",
    "        \"\"\"\n",
    "        self.station_id = station_id\n",
    "        self.station_make = station_make\n",
    "        self.station_model = station_model\n",
    "        self.audio_data = audio_data\n",
    "        self.audio_fs = audio_fs\n",
    "        self.station_lat = station_lat\n",
    "        self.station_lon = station_lon\n",
    "        self.launch_id = launch_id\n",
    "        self.launch_pad_lat = launch_pad_lat\n",
    "        self.launch_pad_lon = launch_pad_lon\n",
    "        self.reported_launch_epoch_s = reported_launch_epoch_s\n",
    "        self.first_sample_epoch_s = first_sample_epoch_s\n",
    "        self.s_aligned_toa_est = s_aligned_toa_est\n",
    "        self.p_aligned_toa_est = p_aligned_toa_est\n",
    "        self.est_prop_dist_km = est_prop_dist_km\n",
    "        self.rocket_type = rocket_type\n",
    "        self.rocket_model_number = rocket_model_number\n",
    "        self.n_srbs = n_srbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229ac12-cdde-49f3-af48-68f03321cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_labels = ASTRALabels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009b7333-68c3-4fbc-840d-9f0506a3f803",
   "metadata": {},
   "source": [
    "With the labels now easily accessible, we'll print out some metadata about the recording(s) in our dataset.\n",
    "\n",
    "Notice how the desired field (in this case: \"launch_id\") is accessed using the column names stored in `ds_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e2ff0-dd86-4bf2-95c5-9defa099049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_ids, launch_counts = np.unique(astra_ds[ds_labels.launch_id], return_counts=True)\n",
    "n_signals = len(astra_ds)\n",
    "n_events = len(launch_ids)\n",
    "print(f\"This dataset contains {n_signals} recording(s) from {n_events} unique launch event(s).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3087a-1474-40b2-bb5b-606ad12ed57f",
   "metadata": {},
   "source": [
    "We can also loop through each launch event in the dataset and print out the metadata associated with individual launches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba43ec-207a-44ff-9c4f-9979324a0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"All launches in PKL file loaded from: {PATH_TO_PKL}\")\n",
    "for launch_id, count in zip(launch_ids, launch_counts):\n",
    "    launch_df = astra_ds[astra_ds[ds_labels.launch_id] == launch_id]\n",
    "    rocket_type = launch_df[ds_labels.rocket_type][launch_df.index[0]]\n",
    "    launch_date = launch_df[ds_labels.reported_launch_epoch_s][launch_df.index[0]]\n",
    "    date_string = (datetime.fromtimestamp(launch_date, tz=timezone.utc)).strftime(\"%d %b %Y\")\n",
    "    print(f\"\\t{rocket_type} launch {launch_id} on {date_string}: {count} recording(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc529ac0-d5a3-4b50-a72f-ff54b2ab6d65",
   "metadata": {},
   "source": [
    "## Section 2: Filtering the Dataset\n",
    "\n",
    "The dataset can be filtered easily using any of the included fields. For example, you could select a subset containing only data recorded from SpaceX Falcon 9 rockets using this line of code:\n",
    "\n",
    "```python\n",
    "falcon9_df = astra_ds[astra_ds[ds_labels.rocket_model_number] == \"F9-B5\"]]\n",
    "```\n",
    "\n",
    "For this tutorial, we'll select a subset of the dataset containing only the data from a single event: NASA's Artemis I launch from November 2022. \n",
    "\n",
    "Each launch event has a unique string called launch ID. This launch ID is usually the official flight number of the launch, but some launches don't have compact flight numbers, in which case the launch ID is an abbreviation of the launch's name. For Artemis I, the launch ID is \"ART-1\". By selecting only those rows with \"ART-1\" in their launch ID field, we create a subset of the dataset containing all available data from our chosen event and no data from any other events in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5ed17-8d7a-4a67-8c38-4ed6b9938453",
   "metadata": {},
   "outputs": [],
   "source": [
    "artemis_launch_id: str = \"ART-1\"\n",
    "artemis_launch_df = astra_ds[astra_ds[ds_labels.launch_id] == artemis_launch_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f40dd-c539-49ef-8ddf-dd5592781564",
   "metadata": {},
   "source": [
    "## Section 3: Plotting ASTRA Data\n",
    "\n",
    "To plot ASTRA audio data, the time array must be reconstructed from the sample rate and epoch time of the first sample.  We use numpy to do this.\n",
    "\n",
    "In the following cell, we'll define a function to plot all available data from a single event. Read through the comments in the function for a detailed explanation of each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94429d-988a-4e2a-a2bd-059b08d36242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a colorblind-friendly color cycle to use in our plots\n",
    "CBF_COLOR_CYCLE = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#984ea3', '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "\n",
    "def single_event_example_plots(launch_df, ds_labels, plot_tfrs=True):\n",
    "    launch_id = launch_df[ds_labels.launch_id][launch_df.index[0]]\n",
    "    # We'll be plotting the waveforms from the launch relative to the mission's reported launch time.\n",
    "    rep_launch_epoch_s = launch_df[ds_labels.reported_launch_epoch_s][launch_df.index[0]]\n",
    "    date_string = (datetime.fromtimestamp(rep_launch_epoch_s, tz=timezone.utc)).strftime(\"%d %B %Y\")\n",
    "    xlabel = f\"Time (s) since launch\"\n",
    "    # For the title, we'll include some information on the launch included in the ASTRA dataset\n",
    "    launch_n_srbs = launch_df[ds_labels.n_srbs][launch_df.index[0]]\n",
    "    launch_rocket_type = launch_df[ds_labels.rocket_type][launch_df.index[0]]\n",
    "    launch_rocket_model = launch_df[ds_labels.rocket_model_number][launch_df.index[0]]\n",
    "    title = f\"Normalized ASTRA audio data from launch {launch_id} on {date_string}\"\n",
    "    title += f\"\\nRocket: {launch_rocket_type}, {launch_rocket_model} configuration ({launch_n_srbs} SRBs)\"\n",
    "    # We'll also set some parameters for the figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    y_adj = 0\n",
    "    y_adj_buff = 2.2\n",
    "    t_max = 0\n",
    "    ticks, tick_labels = [], []\n",
    "    waveform_color, sa_toa_color, pa_toa_color = \"k\", CBF_COLOR_CYCLE[0], CBF_COLOR_CYCLE[1]\n",
    "    # And sort the data by the estimated propagation distance\n",
    "    launch_df = launch_df.sort_values(by=ds_labels.est_prop_dist_km)\n",
    "    for station in launch_df.index:\n",
    "        # We'll start by normalizing the audio data from each station\n",
    "        audio_data = launch_df[ds_labels.audio_data][station]\n",
    "        audio_data_abs_max = np.nanmax(np.abs(launch_df[ds_labels.audio_data][station]))\n",
    "        audio_data = audio_data / audio_data_abs_max\n",
    "        # The epoch time of the first sample of each recording is included in ASTRA\n",
    "        start_time = launch_df[ds_labels.first_sample_epoch_s][station]\n",
    "        # The sample rate of all the audio data in ASTRA is 800 Hz, but it is also included for convenience\n",
    "        fs = launch_df[ds_labels.audio_fs][station]\n",
    "        # With the sample rate, start time, and length of the audio data array, we can reconstruct the time array\n",
    "        epoch_time = (np.array(range(len(audio_data))) / fs) + start_time\n",
    "        # Epoch times are useful, but not very readable on a plot, so we'll convert the array to time since the launch\n",
    "        relative_time = epoch_time - rep_launch_epoch_s\n",
    "        # To speed up plot generation, we'll trim the signal to start at the reported launch time\n",
    "        first_idx = np.argwhere(relative_time >= 0).flatten()[0]\n",
    "        relative_time = relative_time[first_idx:]\n",
    "        audio_data = audio_data[first_idx:]\n",
    "        # We'll also keep track of the maximum time in the recording to set the x-axis limits later\n",
    "        t_max = max(t_max, relative_time[-1])\n",
    "        # The estimated propagation distance in kilometers is also included with each recording in ASTRA, along with the\n",
    "        # ground truth latitudes and longitudes of the launch pad and the station\n",
    "        est_prop_distance_km = launch_df[ds_labels.est_prop_dist_km][station]\n",
    "        # We'll plot the normalized audio data from each station in order of their estimated propagation distances, with\n",
    "        # the y-axis adjusted for each station\n",
    "        ax.plot(relative_time, audio_data + y_adj, lw=1, color=waveform_color)\n",
    "        ticks.append(y_adj)\n",
    "        tick_labels.append(f\"{round(est_prop_distance_km, 1)} km\")\n",
    "        # We'll also plot the estimated arrival times of the start and peak of the rocket launch signal as blue and\n",
    "        # green lines, respectively. For detailed explanations of how these estimates were made, Popenhagen &\n",
    "        # Garces, 2025 (link at the top of this file).\n",
    "        relative_start_toa_estimate = launch_df[ds_labels.s_aligned_toa_est][station] - rep_launch_epoch_s\n",
    "        relative_peak_toa_estimate = launch_df[ds_labels.p_aligned_toa_est][station] - rep_launch_epoch_s\n",
    "        # We'll add labels to the first station's TOA estimate markers for clarity\n",
    "        marker_lines_ylim = (y_adj - y_adj_buff / 2, y_adj + y_adj_buff / 2)\n",
    "        marker_lines_zorder = 10\n",
    "        if station == launch_df.index[0]:\n",
    "            ax.vlines(\n",
    "                ymin=marker_lines_ylim[0],\n",
    "                ymax=marker_lines_ylim[1],\n",
    "                x=relative_start_toa_estimate,\n",
    "                color=sa_toa_color,\n",
    "                zorder=marker_lines_zorder,\n",
    "                label=\"Start-aligned TOA estimate\",\n",
    "                ls=\"-\",\n",
    "                lw=2,\n",
    "            )\n",
    "            ax.vlines(\n",
    "                ymin=marker_lines_ylim[0],\n",
    "                ymax=marker_lines_ylim[1],\n",
    "                x=relative_peak_toa_estimate,\n",
    "                color=pa_toa_color,\n",
    "                zorder=marker_lines_zorder,\n",
    "                label=\"Peak-aligned TOA estimate\",\n",
    "                ls=\"--\",\n",
    "                lw=2,\n",
    "            )\n",
    "        else:\n",
    "            ax.vlines(\n",
    "                ymin=marker_lines_ylim[0],\n",
    "                ymax=marker_lines_ylim[1],\n",
    "                x=[relative_start_toa_estimate, relative_peak_toa_estimate],\n",
    "                color=[sa_toa_color, pa_toa_color],\n",
    "                zorder=marker_lines_zorder,\n",
    "                ls=[\"-\", \"--\"],\n",
    "                lw=2,\n",
    "            )\n",
    "        y_adj -= y_adj_buff\n",
    "        # For each station, we can also plot the continuous wavelet transform (CWT) of the audio data using functions in\n",
    "        # the quantum_inferno module\n",
    "        if not plot_tfrs:\n",
    "            continue\n",
    "        tfr_title = f\"CWT and waveform from launch {launch_id}\"\n",
    "        cwt, cwt_bits, time_s, frequency_cwt_hz = cwt_chirp_from_sig(\n",
    "            sig_wf=audio_data,\n",
    "            frequency_sample_rate_hz=fs,\n",
    "            band_order_nth=3\n",
    "        )\n",
    "        _ = plot_wf_mesh_vert_example(\n",
    "            station_id=f\"{launch_df[ds_labels.station_id][station]} ({est_prop_distance_km:.1f} km)\",\n",
    "            wf_panel_a_sig=audio_data,\n",
    "            wf_panel_a_time=relative_time,\n",
    "            mesh_time=time_s,\n",
    "            mesh_frequency=frequency_cwt_hz,\n",
    "            mesh_panel_b_tfr=cwt_bits,\n",
    "            figure_title=tfr_title,\n",
    "        )\n",
    "    # We'll add some finishing touches to the waveform plot settings\n",
    "    fontsize = 12\n",
    "    ax.set(xlabel=xlabel, xlim=(0, t_max), ylim=(min(ticks) - 1.1 * y_adj_buff / 2, max(ticks) + 1.1 * y_adj_buff / 2))\n",
    "    ax.set_title(title, fontsize=fontsize + 2)\n",
    "    ax.set_xlabel(xlabel, fontsize=fontsize)\n",
    "    ax.yaxis.set_ticks(ticks)\n",
    "    ax.yaxis.set_ticklabels(tick_labels)\n",
    "    ax.tick_params(axis=\"y\", labelsize=\"large\")\n",
    "    ax.tick_params(axis=\"x\", which=\"both\", bottom=True, labelbottom=True, labelsize=\"large\")\n",
    "    ax.legend(frameon=False, bbox_to_anchor=(.99, .99), loc='upper right', fontsize=fontsize)\n",
    "    plt.subplots_adjust()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9fc15-93da-4c07-8aee-033174c192e8",
   "metadata": {},
   "source": [
    "To generate the time domain plots for our example event, we'll call our plotting function with `plot_tfrs=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4cf5bd-152f-4c2d-ae1e-617538d83cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_event_example_plots(launch_df=artemis_launch_df, ds_labels=ds_labels, plot_tfrs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154b3cb-7e11-4be3-9d77-36a72155a576",
   "metadata": {},
   "source": [
    "If we want to generate the time frequency representations, we can call the same plotting function but with `plot_tfrs=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0838b-4041-401c-90f6-a8b1d46b7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_event_example_plots(launch_df=artemis_launch_df, ds_labels=ds_labels, plot_tfrs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c384ee-fdb4-4cea-9b2b-21ba3b3f4950",
   "metadata": {},
   "source": [
    "We can also loop through and generate plots for each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e211f3bf-8312-4999-80c1-cf1929144104",
   "metadata": {},
   "outputs": [],
   "source": [
    "for launch_id in launch_ids:\n",
    "    print(f\"Plotting all available ASTRA audio data from: {launch_id}\")\n",
    "    launch_df = astra_ds[astra_ds[ds_labels.launch_id] == launch_id]\n",
    "    single_event_example_plots(launch_df, ds_labels, plot_tfrs=False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402695c2-90b9-43ef-a61d-08c6958ad9bd",
   "metadata": {},
   "source": [
    "## Section 4: Saving ASTRA Data\n",
    "\n",
    "We can also save a subset of the data to a new pickle (pkl) file. This can be useful in some cases as the full dataset is quite large and may not be needed for all applications.\n",
    "\n",
    "We can save any subset (data recorded at ranges < 30 km, data from only one type of rocket, etc.), but we'll stick with our example subset of data from a single event. For this example, we'll save PKL files of Artemis I data, but this can be modified by simply changing the value of `launch_id_to_save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1823decc-d09e-4d05-b372-95babb2ccd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_id_to_save = \"ART-1\"\n",
    "# Check if the launch id is in the dataset\n",
    "if launch_id_to_save in launch_ids:\n",
    "    subset_to_save = astra_ds[astra_ds[ds_labels.launch_id] == launch_id_to_save]\n",
    "    # Print some details about the subset\n",
    "    n_signals = len(subset_to_save)\n",
    "    rocket_type = subset_to_save[ds_labels.rocket_type][subset_to_save.index[0]]\n",
    "    launch_date = subset_to_save[ds_labels.reported_launch_epoch_s][subset_to_save.index[0]]\n",
    "    date_string = (datetime.fromtimestamp(launch_date, tz=timezone.utc)).strftime(\"%d %b %Y\")\n",
    "    print(f\"Selected event: {rocket_type} launch {launch_id_to_save} on {date_string}: {n_signals} recording(s)\")\n",
    "    \n",
    "    # Save the subset DataFrame to a new pickle file\n",
    "    output_filename = f\"ASTRA_{launch_id_to_save}_{n_signals}.pkl\"\n",
    "    output_path = os.path.join(CURRENT_DIRECTORY, output_filename)\n",
    "    print(f\"Saving subset of ASTRA containing all available data from launch {launch_id_to_save} to: {output_path}\")\n",
    "    subset_to_save.to_pickle(output_path)\n",
    "else:\n",
    "    print(\"Requested data not found. No file saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3cde72-ced9-42ac-90c5-38fe668ada26",
   "metadata": {},
   "source": [
    "We can also save data from a single recording of an event by filtering by station ID as well as launch ID. We'll take a look at the available stations for our selected event and then choose one to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92abdffa-f709-46d3-a861-f75debe57963",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_to_save = astra_ds[astra_ds[ds_labels.launch_id] == launch_id_to_save]\n",
    "print(\"Available signals from the selected launch:\")\n",
    "for station in subset_to_save.index:\n",
    "    station_id = subset_to_save[ds_labels.station_id][station]\n",
    "    dist_km = subset_to_save[ds_labels.est_prop_dist_km][station]\n",
    "    print(f\"\\tStation ID: {station_id} ({dist_km:.1f} km from launch pad)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4e4cf7-704a-4e5b-98eb-6875d86288ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id_to_save: str = \"1637620009\"\n",
    "# Check if the station ID is in the subset DataFrame\n",
    "if station_id_to_save in subset_to_save[ds_labels.station_id].values:\n",
    "    output_filename = f\"ASTRA_{launch_id_to_save}_{station_id_to_save}.pkl\"\n",
    "    subset_to_save = subset_to_save[subset_to_save[ds_labels.station_id] == station_id_to_save]\n",
    "    output_path = os.path.join(CURRENT_DIRECTORY, output_filename)\n",
    "    print(f\"Saving the station {station_id_to_save} data from launch {launch_id_to_save} to: {output_path}\")\n",
    "    subset_to_save.to_pickle(output_path)\n",
    "else:\n",
    "    print(f\"Station ID '{station_id_to_save}' not found in the selected launch subset. No data saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63f51f-d222-4e5a-bf16-666c9c454428",
   "metadata": {},
   "source": [
    "This concludes the tutorial. For more details on ASTRA, see the references listed at the beginning of the tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3_12_4_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
