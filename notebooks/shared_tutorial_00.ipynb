{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9827e2e-92c7-4c19-a2c9-f70e11ebd68b",
   "metadata": {},
   "source": [
    "# Explosion Dataset Tutorial: Loading, Filtering, Plotting, and Saving SHAReD Data\n",
    "\n",
    "This tutorial goes over the basics of how to read, filter, and plot data from the Smartphone High-explosive Audio Recordings Dataset (SHAReD), an open-access dataset.\n",
    "\n",
    "A PKL file containing data from a single event and station is included with this tutorial. The full SHAReD dataset can be downloaded from __[Harvard Dataverse](https://doi.org/10.7910/DVN/ROWODP)__ or __[Soundscapes Archive](https://www.higp.hawaii.edu/archive/isla/UH_Soundscapes/SHAReD/)__.\n",
    "\n",
    "For details on the dataset and the software used to collect and store the data, see __[Takazawa et al. (2024)](https://doi.org/10.3390/s24206688)__ and __[Garces, et al. (2020)](https://doi.org/10.3390/signals3020014)__, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd4c7f7",
   "metadata": {},
   "source": [
    "## Section 0: Prerequisites and Imports\n",
    "The following cell includes the imports necessary to run this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c63af8-7640-43a7-8e3c-f636870e4f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "from quantum_inferno.plot_templates.plot_templates_examples import plot_wf_mesh_vert_example\n",
    "from quantum_inferno.cwt_atoms import cwt_chirp_from_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59505de5-3a00-4310-9ec0-54e3eca99309",
   "metadata": {},
   "source": [
    "## Section 1: Loading the Dataset\n",
    "\n",
    "In the following cell, we'll define the path to the dataset. By default, this path will point to the single-event, single-station subset of SHAReD included with this tutorial.\n",
    "\n",
    "After you've completed the tutorial with this file, feel free to download the full SHAReD dataset and use the last line of the cell to change the 'PATH_TO_PKL' variable to point to its location on your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263ebaa-131d-48e2-9db0-6f309772d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUTORIAL_PICKLE_FILE_NAME = \"SHAReD_tutorial.pkl\"\n",
    "CURRENT_DIRECTORY = os.getcwd()\n",
    "PATH_TO_TUTORIAL_PKL = os.path.join(CURRENT_DIRECTORY, TUTORIAL_PICKLE_FILE_NAME)\n",
    "PATH_TO_PKL = PATH_TO_TUTORIAL_PKL\n",
    "# PATH_TO_PKL = \"<insert path to SHAReD.pkl on your device here>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b11af7-fe5f-435d-8dc6-3bbed89622a4",
   "metadata": {},
   "source": [
    "Once we have the location of the file, we can read the data using the pandas module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a34be7-1910-40b5-bf30-d5dd776e0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_ds = pd.read_pickle(PATH_TO_PKL)\n",
    "shared_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efa308-5fad-4f07-8357-527b22ffd0aa",
   "metadata": {},
   "source": [
    "Each row of the pandas DataFrame contains all data and metadata from a single station for a single event, with individual columns for each of the available fields.\n",
    "\n",
    "To keep track of all the column names, we'll define the 'SHAReDLabels' class, and then initiate an instance of it in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b5767e-add7-4000-841d-6e41e0db6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHAReDLabels:\n",
    "    \"\"\"\n",
    "    A class containing the column names used in the SHAReD dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.event_name: str = \"event_name\"\n",
    "        self.source_yield_kg: str = \"source_yield_kg\"\n",
    "        self.smartphone_id: str = \"smartphone_id\"\n",
    "        self.microphone_time_s: str = \"microphone_time_s\"\n",
    "        self.microphone_data: str = \"microphone_data\"\n",
    "        self.microphone_sample_rate_hz: str = \"microphone_sample_rate_hz\"\n",
    "        self.barometer_time_s: str = \"barometer_time_s\"\n",
    "        self.barometer_data: str = \"barometer_data\"\n",
    "        self.barometer_sample_rate_hz: str = \"barometer_sample_rate_hz\"\n",
    "        self.accelerometer_time_s: str = \"accelerometer_time_s\"\n",
    "        self.accelerometer_data_x: str = \"accelerometer_data_x\"\n",
    "        self.accelerometer_data_y: str = \"accelerometer_data_y\"\n",
    "        self.accelerometer_data_z: str = \"accelerometer_data_z\"\n",
    "        self.accelerometer_sample_rate_hz: str = \"accelerometer_sample_rate_hz\"\n",
    "        self.ambient_microphone_time_s: str = \"ambient_microphone_time_s\"\n",
    "        self.ambient_microphone_data: str = \"ambient_microphone_data\"\n",
    "        self.ambient_barometer_time_s: str = \"ambient_barometer_time_s\"\n",
    "        self.ambient_barometer_data: str = \"ambient_barometer_data\"\n",
    "        self.ambient_accelerometer_time_s: str = \"ambient_accelerometer_time_s\"\n",
    "        self.ambient_accelerometer_data_x: str = \"ambient_accelerometer_data_x\"\n",
    "        self.ambient_accelerometer_data_y: str = \"ambient_accelerometer_data_y\"\n",
    "        self.ambient_accelerometer_data_z: str = \"ambient_accelerometer_data_z\"\n",
    "        self.internal_location_latitude: str = \"internal_location_latitude\"\n",
    "        self.internal_location_longitude: str = \"internal_location_longitude\"\n",
    "        self.external_location_latitude: str = \"external_location_latitude\"\n",
    "        self.external_location_longitude: str = \"external_location_longitude\"\n",
    "        self.source_latitude: str = \"source_latitude\"\n",
    "        self.source_longitude: str = \"source_longitude\"\n",
    "        self.distance_from_explosion_m: str = \"distance_from_explosion_m\"\n",
    "        self.scaled_distance: str = \"scaled_distance\"\n",
    "        self.explosion_detonation_time: str = \"explosion_detonation_time\"\n",
    "        self.internal_clock_offset_s: str = \"internal_clock_offset_s\"\n",
    "        self.smartphone_model: str = \"smartphone_model\"\n",
    "        self.effective_yield_category: str = \"effective_yield_category\"\n",
    "        self.event_id_number: str = \"training_validation_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229ac12-cdde-49f3-af48-68f03321cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_labels = SHAReDLabels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009b7333-68c3-4fbc-840d-9f0506a3f803",
   "metadata": {},
   "source": [
    "With the labels now easily accessible, we'll print out some metadata about the recording(s) in our dataset.\n",
    "\n",
    "Notice how the desired field (in this case: \"event_id_number\") is accessed using the column names stored in `ds_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e2ff0-dd86-4bf2-95c5-9defa099049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_signals = len(shared_ds)\n",
    "event_ids, counts = np.unique(shared_ds[ds_labels.event_id_number], return_counts=True)\n",
    "n_events = len(event_ids)\n",
    "print(f\"This dataset contains {n_signals} recording(s) from {n_events} unique high explosive event(s).\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3087a-1474-40b2-bb5b-606ad12ed57f",
   "metadata": {},
   "source": [
    "Each of the rows in the pandas DataFrame contains all the data collected by a single smartphone during/before a single event and associated metadata. Available fields are listed in the SHAReDLabels class documentation.\n",
    "\n",
    "We can also loop through each event in the dataset and print out the metadata associated with individual explosions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba43ec-207a-44ff-9c4f-9979324a0a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"All events in PKL file loaded from: {PATH_TO_PKL}\")\n",
    "for event_id, count in zip(event_ids, counts):\n",
    "    event_df = shared_ds[shared_ds[ds_labels.event_id_number] == event_id]\n",
    "    eq_yield = event_df[ds_labels.source_yield_kg][event_df.index[0]]\n",
    "    print(f\"\\tEvent {event_id}: {eq_yield} kg TNT eq. yield, {count} recording(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc529ac0-d5a3-4b50-a72f-ff54b2ab6d65",
   "metadata": {},
   "source": [
    "## Section 2: Filtering the Dataset\n",
    "\n",
    "The dataset can be filtered easily using any of the included fields. For example, you could select a subset containing only data recorded from explosions with TNT equivalent yields larger than 20 kg using this line of code:\n",
    "\n",
    "```python\n",
    "subset_df = shared_ds[shared_ds[ds_labels.source_yield_kg] >= 20.]]\n",
    "```\n",
    "\n",
    "For the tutorial, we've selected a subset of the dataset containing only the data from a single event recorded by a single smartphone.\n",
    "\n",
    "To filter by event, event ID numbers ('event_id_number' in SHAReDLabels) must be used as the event ID numbers are unique integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5ed17-8d7a-4a67-8c38-4ed6b9938453",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_event_id: int = 26\n",
    "example_df = shared_ds[shared_ds[ds_labels.event_id_number] == example_event_id]\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad7cc6e",
   "metadata": {},
   "source": [
    "Each event also has an associated event name ('event_name' in SHAReDLabels). Event names are strings contianing some metadata about the event. They are not necessarily unique to an event, however, and thus cannot be used to filter for a specific event.\n",
    "\n",
    "All the events in SHAReD were recorded in collaboration with either Idaho National Laboratory (INL) or Nevada National Security Site (NNSS). Each event name starts contains ID strings starting with either \"INL\" (for events recorded in collaboration with INL) or \"NNSS\" (for events recorded in collaboration with NNSS). INL events contain information on the TNT equivalent source yield of the explosion, while NNSS events do not. All NNSS events share the same event name (\"NNSS\"), but can be differentiated by their unique event ID numbers.\n",
    "\n",
    "Our example event is an INL event, so we can print out the source yield along with some other metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa98a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name = example_df[ds_labels.event_name][example_df.index[0]]\n",
    "print(f\"\\nExample event name: {event_name}, event ID number: {example_event_id}\")\n",
    "source_yield = example_df[ds_labels.source_yield_kg][example_df.index[0]]\n",
    "smartphone_id = example_df[ds_labels.smartphone_id][example_df.index[0]]\n",
    "dist_m = example_df[ds_labels.distance_from_explosion_m][example_df.index[0]]\n",
    "print(f\"{source_yield} kg TNT eq. detonation recorded by station {smartphone_id} at {round(dist_m)}m range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f40dd-c539-49ef-8ddf-dd5592781564",
   "metadata": {},
   "source": [
    "## Section 3: Plotting SHAReD Data\n",
    "\n",
    "In the following cell, we'll define a function to plot all available data from a single station. Read through the comments in the function for a detailed explanation of each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94429d-988a-4e2a-a2bd-059b08d36242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a colorblind-friendly color cycle to use in our plots\n",
    "CBF_COLOR_CYCLE = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#984ea3', '#999999', '#e41a1c', '#dede00']\n",
    "# fontsize to use in plots\n",
    "fontsize = 12\n",
    "\n",
    "def demean_norm(signal: np.ndarray) -> np.ndarray:\n",
    "    signal = signal - np.nanmean(signal)\n",
    "    return signal / np.nanmax(np.abs(signal))\n",
    "\n",
    "def multimodal_time_domain_plot(station_df, ds_labels):\n",
    "    station_idx = station_df.index[0]\n",
    "    event_name = station_df[ds_labels.event_name][station_idx]\n",
    "    event_id = station_df[ds_labels.event_id_number][station_idx]\n",
    "    station_id = station_df[ds_labels.smartphone_id][station_idx]\n",
    "    print(f\"\\nEvent name: {event_name}, event ID number: {event_id}, station ID: {station_id}\")\n",
    "    source_yield = station_df[ds_labels.source_yield_kg][station_idx]\n",
    "    if source_yield is None or np.isnan(source_yield):\n",
    "        title_header = f\"SHAReD event {event_name} (source yield not included)\"\n",
    "    else:\n",
    "        title_header = f\"SHAReD event {event_name} ({source_yield} kg TNT eq.)\"\n",
    "    # We'll plot the data from each sensor for both the \"explosion\" and \"ambient\" segments of data.\n",
    "    t000 = station_df[ds_labels.explosion_detonation_time][station_idx]\n",
    "    t00 = station_df[ds_labels.microphone_time_s][station_idx][0] - t000\n",
    "    dt0 = station_df[ds_labels.microphone_time_s][station_idx][-1] - t000\n",
    "    dist_m = station_df[ds_labels.distance_from_explosion_m][station_idx]\n",
    "\n",
    "    title_line2 = f\"\\nDistance from source: {int(dist_m)} m, \"\n",
    "    title_line2 += f\"scaled distance: {station_df[ds_labels.scaled_distance][station_idx]:.2f} m/kg^(1/3)\"\n",
    "    fig, ax = plt.subplots(3, 2, figsize=(10, 7), sharex='col', sharey=True)\n",
    "    fig.suptitle(f\"Normalized signals from {title_header}{title_line2}\", fontsize=fontsize + 2)\n",
    "    ax[0, 1].plot(station_df[ds_labels.microphone_time_s][station_idx] - t000,\n",
    "                  demean_norm(station_df[ds_labels.microphone_data][station_idx]),\n",
    "                  lw=1, color=\"k\")\n",
    "    ax[1, 1].plot(station_df[ds_labels.barometer_time_s][station_idx] - t000,\n",
    "                  demean_norm(station_df[ds_labels.barometer_data][station_idx]),\n",
    "                  lw=1, color=\"k\")\n",
    "    ax[2, 1].plot(station_df[ds_labels.accelerometer_time_s][station_idx] - t000,\n",
    "                  demean_norm(station_df[ds_labels.accelerometer_data_x][station_idx]),\n",
    "                  lw=1, label=\"x-axis\", color=CBF_COLOR_CYCLE[0])\n",
    "    ax[2, 1].plot(station_df[ds_labels.accelerometer_time_s][station_idx] - t000,\n",
    "                  demean_norm(station_df[ds_labels.accelerometer_data_y][station_idx]),\n",
    "                  lw=1, label=\"y-axis\", color=CBF_COLOR_CYCLE[1])\n",
    "    ax[2, 1].plot(station_df[ds_labels.accelerometer_time_s][station_idx] - t000,\n",
    "                  demean_norm(station_df[ds_labels.accelerometer_data_z][station_idx]),\n",
    "                  lw=1, label=\"z-axis\", color=CBF_COLOR_CYCLE[2])\n",
    "    \n",
    "    ax[2, 1].legend()\n",
    "    ax[0, 1].set(xlim=(t00, dt0), ylim=(-1.1, 1.1))\n",
    "    ax[0, 1].tick_params(axis=\"y\", labelsize=\"large\", left=True, labelleft=True)\n",
    "    ax[0, 1].set_title(f\"Explosion microphone\", fontsize=fontsize)\n",
    "    ax[0, 1].set_ylabel(\"Norm\", fontsize=fontsize)\n",
    "    ax[1, 1].set_title(\"Explosion barometer\", fontsize=fontsize)\n",
    "    ax[1, 1].tick_params(axis=\"y\", labelsize=\"large\", left=True, labelleft=True)\n",
    "    ax[1, 1].set_ylabel(\"Norm\", fontsize=fontsize)\n",
    "    ax[2, 1].set_title(\"Explosion accelerometer\", fontsize=fontsize)\n",
    "    ax[2, 1].tick_params(axis=\"y\", labelsize=\"large\", left=True, labelleft=True)\n",
    "    ax[2, 1].tick_params(axis=\"x\", which=\"both\", bottom=True, labelbottom=True, labelsize=\"large\")\n",
    "    ax[2, 1].set_ylabel(\"Norm\", fontsize=fontsize)\n",
    "    ax[2, 1].set_xlabel(\"Time (s) since event\", fontsize=fontsize)\n",
    "\n",
    "    t10 = station_df[ds_labels.ambient_microphone_time_s][station_idx][0]\n",
    "    dt1 = station_df[ds_labels.ambient_microphone_time_s][station_idx][-1] - t10\n",
    "    ax[0, 0].plot(station_df[ds_labels.ambient_microphone_time_s][station_idx] - t10,\n",
    "                  demean_norm(station_df[ds_labels.ambient_microphone_data][station_idx]),\n",
    "                  lw=1, color=\"k\")\n",
    "    ax[1, 0].plot(station_df[ds_labels.ambient_barometer_time_s][station_idx] - t10,\n",
    "                  demean_norm(station_df[ds_labels.ambient_barometer_data][station_idx]),\n",
    "                  lw=1, color=\"k\")\n",
    "    ax[2, 0].plot(station_df[ds_labels.ambient_accelerometer_time_s][station_idx] - t10,\n",
    "                  demean_norm(station_df[ds_labels.ambient_accelerometer_data_x][station_idx]),\n",
    "                  lw=1, label=\"x-axis\", color=CBF_COLOR_CYCLE[0])\n",
    "    ax[2, 0].plot(station_df[ds_labels.ambient_accelerometer_time_s][station_idx] - t10,\n",
    "                  demean_norm(station_df[ds_labels.ambient_accelerometer_data_y][station_idx]),\n",
    "                  lw=1, label=\"y-axis\", color=CBF_COLOR_CYCLE[1])\n",
    "    ax[2, 0].plot(station_df[ds_labels.ambient_accelerometer_time_s][station_idx] - t10,\n",
    "                  demean_norm(station_df[ds_labels.ambient_accelerometer_data_z][station_idx]),\n",
    "                  lw=1, label=\"z-axis\", color=CBF_COLOR_CYCLE[2])\n",
    "\n",
    "    ax[0, 0].set(xlim=(0, dt1), ylim=(-1.1, 1.1))\n",
    "    ax[0, 0].tick_params(axis=\"y\", labelsize=\"large\", left=True, labelleft=True)\n",
    "    ax[0, 0].set_title(f\"Ambient microphone\", fontsize=fontsize)\n",
    "    ax[0, 0].set_ylabel(\"Norm\", fontsize=fontsize)\n",
    "    ax[1, 0].set_title(\"Ambient barometer\", fontsize=fontsize)\n",
    "    ax[1, 0].tick_params(axis=\"y\", labelsize=\"large\", left=True, labelleft=True)\n",
    "    ax[1, 0].set_ylabel(\"Norm\", fontsize=fontsize)\n",
    "    ax[2, 0].set_title(\"Ambient accelerometer\", fontsize=fontsize)\n",
    "    ax[2, 0].tick_params(axis=\"y\", labelsize=\"large\", left=True, labelleft=True)\n",
    "    ax[2, 0].tick_params(axis=\"x\", which=\"both\", bottom=True, labelbottom=True, labelsize=\"large\")\n",
    "    ax[2, 0].set_ylabel(\"Norm\", fontsize=fontsize)\n",
    "    ax[2, 0].set_xlabel(\"Time (s)\", fontsize=fontsize)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9fc15-93da-4c07-8aee-033174c192e8",
   "metadata": {},
   "source": [
    "In the tutorial PKL file, only the data from one station are included, but we'll loop through the indices anyway to illustrate how to generate the plots for all stations associated with an event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4cf5bd-152f-4c2d-ae1e-617538d83cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = example_df.sort_values(by=ds_labels.distance_from_explosion_m)\n",
    "event_stations = example_df[ds_labels.smartphone_id]\n",
    "for station_id in event_stations:\n",
    "    example_station_df = example_df[example_df[ds_labels.smartphone_id] == station_id]\n",
    "    multimodal_time_domain_plot(station_df=example_station_df, ds_labels=ds_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154b3cb-7e11-4be3-9d77-36a72155a576",
   "metadata": {},
   "source": [
    "We can also generate time-frequency representations of the data. In the next cell, we'll use the audio data from our example file to illustrate how to do this quickly and easily using functions from the quantum_inferno module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0838b-4041-401c-90f6-a8b1d46b7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the rows\n",
    "for row_index in example_df.index:\n",
    "    # grab the values from the relevant metadata fields\n",
    "    event_name = example_df[ds_labels.event_name][row_index]\n",
    "    source_yield = example_df[ds_labels.source_yield_kg][row_index]\n",
    "    dist_m = example_df[ds_labels.distance_from_explosion_m][row_index]\n",
    "    station_id = example_df[ds_labels.smartphone_id][row_index]\n",
    "    # standardize the time array for cleaner visualization\n",
    "    relative_time = example_df[ds_labels.microphone_time_s][row_index] - example_df[ds_labels.microphone_time_s][row_index][0]\n",
    "    # demean and normalize the audio data for cleaner visualization\n",
    "    audio_data = demean_norm(example_df[ds_labels.microphone_data][row_index])\n",
    "    # calculate and plot the continuous wavelet transform using the quantum_inferno module\n",
    "    cwt, cwt_bits, time_s, frequency_cwt_hz = cwt_chirp_from_sig(\n",
    "        sig_wf=audio_data,\n",
    "        frequency_sample_rate_hz=example_df[ds_labels.microphone_sample_rate_hz][row_index],\n",
    "        band_order_nth=3,\n",
    "        cwt_type=\"conv\"\n",
    "    )\n",
    "    tfr_title = f\"CWT and waveform for {event_name} ({source_yield} kg TNT eq.)\"\n",
    "    _ = plot_wf_mesh_vert_example(\n",
    "        station_id=f\"{station_id} ({round(dist_m)} m)\",\n",
    "        wf_panel_a_sig=audio_data,\n",
    "        wf_panel_a_time=relative_time,\n",
    "        mesh_time=time_s,\n",
    "        mesh_frequency=frequency_cwt_hz,\n",
    "        mesh_panel_b_tfr=cwt_bits,\n",
    "        figure_title=tfr_title,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402695c2-90b9-43ef-a61d-08c6958ad9bd",
   "metadata": {},
   "source": [
    "## Section 4: Saving SHAReD Data\n",
    "\n",
    "We can save a subset of the data to a new pickle (.pkl) file. This can be useful in some cases as the full dataset is quite large and may not be needed for all applications.\n",
    "\n",
    "We can save any subset (data from detonations > 10 kg TNT eq., data from only a single station, etc.), but we'll stick with our example subset of data from a single event and station. For this example, we'll save a pickle file of data from our example event and station (event ID number 26, station ID 1637681008), but this can be modified by simply changing the values of `event_id_number_to_save` and `station_id_to_save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc276a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_id_to_save: int = 26\n",
    "station_id_to_save: str = \"1637681008\"\n",
    "# check if the event id is in the dataset\n",
    "event_ids = np.unique(shared_ds[ds_labels.event_id_number])\n",
    "if event_id_to_save in event_ids:\n",
    "    subset_to_save = shared_ds[shared_ds[ds_labels.event_id_number] == event_id_to_save]\n",
    "    # check if the station id is in the subset\n",
    "    station_ids = np.unique(subset_to_save[ds_labels.smartphone_id])\n",
    "    if station_id_to_save in station_ids:\n",
    "        subset_to_save = subset_to_save[subset_to_save[ds_labels.smartphone_id] == station_id_to_save]\n",
    "        output_filename = f\"SHAReD_event{event_id_to_save}_{station_id_to_save}.pkl\"\n",
    "        output_path = os.path.join(CURRENT_DIRECTORY, output_filename)\n",
    "        subset_to_save.to_pickle(output_path)\n",
    "        print(f\"Subset of SHAReD containing event {event_id_to_save} data from station {station_id_to_save} saved to: {output_path}\")\n",
    "    else:\n",
    "        print(f\"Station {station_id_to_save} not found in data from event number {event_id_to_save}. No data saved.\")\n",
    "else:\n",
    "    print(f\"Data from event number {event_id_to_save} not found in dataset. No data saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63f51f-d222-4e5a-bf16-666c9c454428",
   "metadata": {},
   "source": [
    "This concludes the tutorial. For more details on SHAReD, see the references listed at the beginning of the tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_3_12_4_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
