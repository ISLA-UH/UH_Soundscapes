{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9827e2e-92c7-4c19-a2c9-f70e11ebd68b",
   "metadata": {},
   "source": [
    "# Hypersonic Dataset Tutorial: Loading, Filtering, Plotting, and Saving Data from the OSIRIS-REx Re-entry\n",
    "\n",
    "This tutorial goes over the basics of how to read, filter, and plot data collected during the atmospheric re-entry over Nevada and Utah of NASA's OSIRIS-REx sample return capsule.\n",
    "\n",
    "A file containing data from a single station is included with this tutorial. The full  dataset can be downloaded from __[Google Drive](https://drive.google.com/drive/folders/1QKHUzdT0et6xpKXm8LFOmHJ9_gx0J2ib?usp=sharing)__ (contact Sarah Popenhagen at spopen@hawaii.edu for folder access).\n",
    "\n",
    "The OREX data collection campaign was a collaboration between multiple institutions that resulted in numerous publications, a few of which are listed below.\n",
    "\n",
    "__[Silber, E.A. *et al.* Geophysical Observations of the 2023 September 24 OSIRIS-REx Sample Return Capsule Reentry. *Planet. Sci. J.* **5**, 213 (2024).](https://doi.org/10.3847/PSJ/ad5b5e)__\n",
    "\n",
    "__[Silber, E.A. & Bowman, D.C. Along‐Trajectory Acoustic Signal Variations Observed During the Hypersonic Re‐Entry of the OSIRIS‐REx Sample Return Capsule. *Seismol. Res. Lett.* **XX**, 1-13 (2025).](https://doi.org/10.1785/0220250014)__\n",
    "\n",
    "__[Fernando, B. *et al.* Seismoacoustic measurements of the OSIRIS-REx re-entry with an off-grid Raspberry PiShake. *Seismica* **3**, 1 (2024).](https://doi.org/10.26443/seismica.v3i1.1154)__\n",
    "\n",
    "__[KC, R.J. *et al.* Acoustic Observations of the OSIRIS-REx Sample Return Capsule Re-Entry from Wendover Airport. *Seismol. Res. Lett.* **XX**, 1-14 (2025).](https://doi.org/10.1785/0220250019)__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd4c7f7",
   "metadata": {},
   "source": [
    "## Section 0: Prerequisites and Imports\n",
    "The following cell includes the imports necessary to run this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c63af8-7640-43a7-8e3c-f636870e4f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import quantum_inferno.plot_templates.plot_base as ptb\n",
    "from quantum_inferno.plot_templates.plot_templates import plot_mesh_wf_vert\n",
    "from quantum_inferno.styx_stx import tfr_stx_fft\n",
    "from quantum_inferno.utilities.rescaling import to_log2_with_epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59505de5-3a00-4310-9ec0-54e3eca99309",
   "metadata": {},
   "source": [
    "## Section 1: Loading the Dataset\n",
    "\n",
    "In the following cell, we'll define the path to the dataset. By default, this path will point to the single-station subset of data included with this tutorial.\n",
    "\n",
    "After you've completed the tutorial with this file, feel free to download the full dataset and use the last line of the cell to change the 'PATH_TO_NPZ' variable to point to its location on your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263ebaa-131d-48e2-9db0-6f309772d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUTORIAL_NPZ_FILE_NAME = \"OREX_tutorial.npz\"\n",
    "CURRENT_DIRECTORY = os.getcwd()\n",
    "PATH_TO_TUTORIAL_NPZ = os.path.join(CURRENT_DIRECTORY, TUTORIAL_NPZ_FILE_NAME)\n",
    "PATH_TO_NPZ = PATH_TO_TUTORIAL_NPZ\n",
    "# PATH_TO_NPZ = \"<insert path to 'orex_best_mics_800hz_1024pt.npz' on your device here>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b11af7-fe5f-435d-8dc6-3bbed89622a4",
   "metadata": {},
   "source": [
    "Once we have the location of the file, we can read the data by passing `PATH_TO_NPZ` and allow_pickle=True to the numpy function __[np.load()](https://numpy.org/doc/stable/reference/generated/numpy.load.html)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a34be7-1910-40b5-bf30-d5dd776e0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orex_npz: np.ndarray = np.load(PATH_TO_NPZ, allow_pickle=True)\n",
    "orex_npz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efa308-5fad-4f07-8357-527b22ffd0aa",
   "metadata": {},
   "source": [
    "In the output of the previous cell, we see the NPZ file's keys: \"station_ids\", \"station_labels\", \"station_wf\", and \"station_epoch_s\". For ease of use, we'll define a class containing these keys, as well as a few others that will become useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b5767e-add7-4000-841d-6e41e0db6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OREXLabels:\n",
    "    \"\"\"\n",
    "    A class containing the keys used in the OSIRIS-REx NPZ file.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            station_id: str = \"station_ids\",\n",
    "            station_label: str = \"station_labels\",\n",
    "            station_make: str = \"station_make\",\n",
    "            station_model: str = \"station_model_number\",\n",
    "            station_network: str = \"deployment_network\",\n",
    "            audio_data: str = \"station_wf\",\n",
    "            audio_epoch_s: str = \"station_epoch_s\",\n",
    "            audio_fs: str = \"audio_sample_rate_nominal_hz\",\n",
    "            event_id: str = \"event_id\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Defaults should be left in place for most uses.\n",
    "        :param station_id: key associated with the unique ID string of the station used to record the signal\n",
    "        :param station_label: key associated with the descriptive label string of the station\n",
    "        :param station_make: key associated with the recording smartphone's make\n",
    "        :param station_model: key associated with the recording smartphone's model\n",
    "        :param station_network: key associated with the network on which the smartphone was deployed\n",
    "        :param audio_data: key associated with the audio waveform of the signal\n",
    "        :param audio_epoch_s: key associated with the time array of the audio waveform in epoch seconds\n",
    "        :param audio_fs: key associated with the sample rate of the audio data in Hertz\n",
    "        :param event_id: key associated with the unique ID string of the event associated with the signal\n",
    "        \"\"\"\n",
    "        self.station_id = station_id\n",
    "        self.station_label = station_label\n",
    "        self.station_make = station_make\n",
    "        self.station_model = station_model\n",
    "        self.station_network = station_network\n",
    "        self.audio_data = audio_data\n",
    "        self.audio_epoch_s = audio_epoch_s\n",
    "        self.audio_fs = audio_fs\n",
    "        self.event_id = event_id\n",
    "\n",
    "ds_labels = OREXLabels()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4963c1df",
   "metadata": {},
   "source": [
    "Using these labels as column names, we'll construct a pandas DataFrame to organize the data and metadata from the NPZ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0467a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "orex_df = pd.DataFrame()\n",
    "for field in orex_npz.files:\n",
    "    field_element = orex_npz[field]\n",
    "    if len(field_element.shape) > 1:\n",
    "        field_element = [field_element[i, :] for i in range(field_element.shape[0])]\n",
    "    orex_df[field] = field_element\n",
    "orex_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c05560",
   "metadata": {},
   "source": [
    "We'll also include ground truth values for the `event_id` and `audio_fs` fields. All audio data in the OREX NPZ file were recorded at 800 Hz, and all are associated with the OSIRIS-REx reentry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0dca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_fs_hz: float = 800.0\n",
    "orex_event_id: str = \"OREX\"\n",
    "n_signals = len(orex_df)\n",
    "orex_df[ds_labels.audio_fs] = [audio_fs_hz] * n_signals\n",
    "orex_df[ds_labels.event_id] = [orex_event_id] * n_signals\n",
    "orex_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b08e83",
   "metadata": {},
   "source": [
    "The descriptive strings associated with the `station_label` field contain information about the general location of the station and the model of the phone. \n",
    "\n",
    "For example, the station label \"WEND S22-01\" indicates that the associated data were recorded by a Samsung Galaxy S22 smartphone as part of the Wendover deployment.\n",
    "\n",
    "With the labels now easily accessible, we'll print out some metadata about the recording(s) in our dataset in the next cell.\n",
    "\n",
    "Notice how the desired fields are accessed using the column names stored in `ds_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e2ff0-dd86-4bf2-95c5-9defa099049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_signals = len(orex_df)\n",
    "print(f\"This dataset contains {n_signals} recording(s) from the OSIRIS-REx atmospheric reentry:\")\n",
    "for idx in orex_df.index:\n",
    "    signal_length_s = orex_df[ds_labels.audio_epoch_s][idx][-1] - orex_df[ds_labels.audio_epoch_s][idx][0]\n",
    "    station_label_info = orex_df[ds_labels.station_label][idx].split(\" \")\n",
    "    deployment_net = station_label_info[0]\n",
    "    smartphone_model = station_label_info[-1].split(\"-\")[0]\n",
    "    print(f\"\\nStation {orex_df[ds_labels.station_id][idx]}:\")\n",
    "    print(f\"\\tSignal length: {signal_length_s} s\")\n",
    "    print(f\"\\tSmartphone model: {smartphone_model}\")\n",
    "    print(f\"\\tDeployment network: {deployment_net}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18410177",
   "metadata": {},
   "source": [
    "To facillitate filtering of the dataset, we'll extract this information from the station labels and add it to our DataFrame using list comprehension and the functions defined in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026b4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_station_model(station_label_string):\n",
    "    return station_label_string.split(\" \")[-1].split(\"-\")[0]\n",
    "\n",
    "def get_station_network(station_label_string):\n",
    "    return station_label_string.split(\" \")[0]\n",
    "\n",
    "orex_df[ds_labels.station_model] = [get_station_model(sls) for sls in orex_df[ds_labels.station_label]]\n",
    "orex_df[ds_labels.station_network] = [get_station_network(sls) for sls in orex_df[ds_labels.station_label]]\n",
    "orex_df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc529ac0-d5a3-4b50-a72f-ff54b2ab6d65",
   "metadata": {},
   "source": [
    "## Section 2: Filtering the Dataset\n",
    "\n",
    "The dataset can be filtered easily using any of the included fields. For example, you could select a subset containing only data from stations included in the \"WEND\" network deployed southwest of Wendover, UT during the event.\n",
    "\n",
    "```python\n",
    "wend_df = orex_df[orex_df[ds_labels.station_network] == \"WEND\"]]\n",
    "```\n",
    "\n",
    "For the tutorial, we've selected a subset of the dataset containing only the data recorded by a single station. To illustrate the methods, however, we'll filter the tutorial dataset to select only the data associated with our example station. \n",
    "\n",
    "If you're using the full dataset, this will create a subset of the data identical to the tutorial dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5ed17-8d7a-4a67-8c38-4ed6b9938453",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_station_id: str = \"1637622001\"\n",
    "example_df = orex_df[orex_df[ds_labels.station_id] == example_station_id]\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f40dd-c539-49ef-8ddf-dd5592781564",
   "metadata": {},
   "source": [
    "## Section 3: Plotting OREX Data\n",
    "\n",
    "In the next cell, we'll define a function to plot the audio data from a single station in the time domain. Read through the comments in the function for a detailed explanation of each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94429d-988a-4e2a-a2bd-059b08d36242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fontsize to use in plots\n",
    "fontsize = 12\n",
    "\n",
    "def demean_norm(signal: np.ndarray) -> np.ndarray:\n",
    "    signal = signal - np.nanmean(signal)\n",
    "    return signal / np.nanmax(np.abs(signal))\n",
    "\n",
    "def single_station_time_domain_plot(station_df, ds_labels):\n",
    "    station_idx = station_df.index[0]\n",
    "    event_id = station_df[ds_labels.event_id][station_idx]\n",
    "    station_id = station_df[ds_labels.station_id][station_idx]\n",
    "    station_net = station_df[ds_labels.station_network][station_idx]\n",
    "    station_label = station_df[ds_labels.station_label][station_idx]\n",
    "    print(f\"\\nEvent name: {event_id}, deployment network: {station_net}, station ID: {station_id}\")\n",
    "    # To make the visualization cleaner, we'll plot the audio data against time relative to the first sample\n",
    "    t0 = station_df[ds_labels.audio_epoch_s][station_idx][0]\n",
    "    relative_time_s = station_df[ds_labels.audio_epoch_s][station_idx] - t0\n",
    "    date_string = (datetime.fromtimestamp(t0, tz=timezone.utc)).strftime(\"%Y-%b-%d %H:%M:%S\")\n",
    "    # We'll also demean and normalized the audio waveform to the range [-1, 1]\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "    fig.suptitle(f\"Audio waveform from {event_id}\\nStation {station_id} ({station_label})\", fontsize=fontsize + 2)\n",
    "    ax.plot(relative_time_s, demean_norm(station_df[ds_labels.audio_data][station_idx]), lw=1, color=\"k\")\n",
    "    ax.set(xlim=(0.0, relative_time_s[-1]), ylim=(-1.1, 1.1))\n",
    "    ax.tick_params(axis=\"y\", labelsize=\"large\", left=True, labelleft=True)\n",
    "    ax.tick_params(axis=\"x\", labelsize=\"large\", bottom=True, labelbottom=True)\n",
    "    ax.set_ylabel(\"Norm\", fontsize=fontsize)\n",
    "    ax.set_xlabel(f\"Time (s) since {date_string} UTC\", fontsize=fontsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9fc15-93da-4c07-8aee-033174c192e8",
   "metadata": {},
   "source": [
    "In the tutorial subset, only the data from one station are included, but we'll loop through the indices anyway to illustrate how to generate plots for all stations in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4cf5bd-152f-4c2d-ae1e-617538d83cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = example_df.sort_values(by=ds_labels.station_label)\n",
    "event_stations = example_df[ds_labels.station_id]\n",
    "for station_id in event_stations:\n",
    "    example_station_df = example_df[example_df[ds_labels.station_id] == station_id]\n",
    "    single_station_time_domain_plot(station_df=example_station_df, ds_labels=ds_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154b3cb-7e11-4be3-9d77-36a72155a576",
   "metadata": {},
   "source": [
    "We can also generate time-frequency representations of the data. In the next cell, we'll use our example audio signal to illustrate how to do this quickly and easily using functions from the quantum_inferno module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0838b-4041-401c-90f6-a8b1d46b7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order sets the atom resolution\n",
    "order_number_input: int = 3\n",
    "\n",
    "# loop through the rows\n",
    "for row_index in example_df.index:\n",
    "    fs = example_df[ds_labels.audio_fs][row_index]\n",
    "    # Averaging window sets lowest frequency of analysis (lower passband edge).\n",
    "    fft_duration_ave_window_points_pow2 = 8*1024\n",
    "    print(f'Averaging period = {fft_duration_ave_window_points_pow2 / fs} s')\n",
    "    frequency_resolution_fft_hz = fs / fft_duration_ave_window_points_pow2\n",
    "    # Normalize the audio waveform and time array\n",
    "    sig_wf = demean_norm(example_df[ds_labels.audio_data][row_index])\n",
    "    t0 = example_df[ds_labels.audio_epoch_s][row_index][0]\n",
    "    sig_time_s = example_df[ds_labels.audio_epoch_s][row_index] - t0\n",
    "    # Compute Stockwell transform\n",
    "    [stx_complex, _, frequency_stx_hz, _, _] = tfr_stx_fft(\n",
    "        sig_wf=sig_wf,\n",
    "        time_sample_interval=1 / fs,\n",
    "        frequency_min=frequency_resolution_fft_hz,\n",
    "        frequency_max=fs / 2,\n",
    "        scale_order_input=order_number_input,\n",
    "        n_fft_in=fft_duration_ave_window_points_pow2,\n",
    "        is_geometric=True,\n",
    "        is_inferno=False,\n",
    "    )\n",
    "\n",
    "    stx_power = 2 * np.abs(stx_complex) ** 2\n",
    "    mic_stx_bits = to_log2_with_epsilon(np.sqrt(stx_power))\n",
    "\n",
    "    # Select plot frequencies\n",
    "    fmin_plot = 4 * frequency_resolution_fft_hz  # Octaves above the lowest frequency of analysis\n",
    "    fmax_plot = fs / 2  # Nyquist\n",
    "\n",
    "    # Plot the STX\n",
    "    wf_base = ptb.WaveformPlotBase(\n",
    "        f\"{example_df[ds_labels.station_id][row_index]} ({example_df[ds_labels.station_label][row_index]})\", \n",
    "        f\"Stockwell transform of {example_df[ds_labels.event_id][row_index]} audio data\")\n",
    "    wf_panel = ptb.WaveformPanel(sig_wf, sig_time_s)\n",
    "    mesh_base = ptb.MeshBase(sig_time_s, frequency_stx_hz, frequency_hz_ymin=fmin_plot, frequency_hz_ymax=fmax_plot)\n",
    "    mesh_panel = ptb.MeshPanel(mic_stx_bits, colormap_scaling=\"range\", cbar_units=\"log$_2$(Power)\")\n",
    "    stx = plot_mesh_wf_vert(mesh_base, mesh_panel, wf_base, wf_panel)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402695c2-90b9-43ef-a61d-08c6958ad9bd",
   "metadata": {},
   "source": [
    "## Section 4: Saving OREX Data\n",
    "\n",
    "We can save a subset of the data to a new PKL or NPZ file. This can be useful in cases where memory is limited and the full dataset is not required.\n",
    "\n",
    "We can save any subset (data from all stations in a network, data recorded by S22 phones, etc.), but we'll stick with our example subset of data from only station 1637622001, and only save the fields that are included in the original NPZ dataset file.\n",
    "\n",
    "The code in the next cell can be modified easily to save data from a different station by simply changing the value of `station_id_to_save`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc276a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id_to_save: str = \"1637622001\"\n",
    "columns_to_save = [ds_labels.audio_data, ds_labels.audio_epoch_s, ds_labels.station_id, ds_labels.station_label]\n",
    "\n",
    "# check if the station id is in the subset\n",
    "station_ids = np.unique(orex_df[ds_labels.station_id])\n",
    "if station_id_to_save in station_ids:\n",
    "    # filtering\n",
    "    subset_to_save = orex_df[orex_df[ds_labels.station_id] == station_id_to_save]\n",
    "    subset_to_save = subset_to_save[columns_to_save]\n",
    "    # set filenames\n",
    "    output_filename = f\"OREX_{station_id_to_save}\"\n",
    "    output_path_pkl = os.path.join(CURRENT_DIRECTORY, f\"{output_filename}.pkl\")\n",
    "    output_path_npz = os.path.join(CURRENT_DIRECTORY, f\"{output_filename}.npz\")\n",
    "    subset_to_save.to_pickle(output_path_pkl)\n",
    "    print(f\"OREX data from station {station_id_to_save} saved to: {output_path_pkl}\")\n",
    "    np.savez(output_path_npz, \n",
    "             **{ds_labels.audio_data: subset_to_save[ds_labels.audio_data], \n",
    "                ds_labels.audio_epoch_s: subset_to_save[ds_labels.audio_epoch_s], \n",
    "                ds_labels.station_id: subset_to_save[ds_labels.station_id], \n",
    "                ds_labels.station_label: subset_to_save[ds_labels.station_label]})\n",
    "    print(f\"OREX data from station {station_id_to_save} saved to: {output_path_npz}\")\n",
    "else:\n",
    "    print(f\"Station {station_id_to_save} not found in OREX data file. No data saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d63f51f-d222-4e5a-bf16-666c9c454428",
   "metadata": {},
   "source": [
    "This concludes the tutorial. For more details on data from OSIRIS-REx, see the references listed at the beginning of the tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
